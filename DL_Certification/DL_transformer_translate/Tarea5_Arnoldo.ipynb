{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escuela de ML y DL Módulo 2\n",
    "# Tarea 5. Traductor utilizando un transformer.\n",
    "# Arnoldo Fernando Chue Sánchez\n",
    "# arnoldwork20@gmail.com\n",
    "# Agosto de 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "1. Planteamiento del problema\n",
    "2. Planteamiento de la solución\n",
    "3. Ejemplo de ejecución\n",
    "4. Conclusiones\n",
    "5. Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Planteamiento del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar un diccionario.pkl para construir un keras-transformer como traductor, de un idioma fuente (francés, alemán, italiano, etc.) al lenguaje español, deberá hacer lo siguiente:\n",
    "- Buscar el diccionario para el idioma fuente a español\n",
    "- Cargarlo en la libreta TransformerTraductor.ipynb\n",
    "- Entrenar el modelo transformer\n",
    "- Buscar el menor error (épocas, dropout, tamaño de batch, otros parámetros)\n",
    "- Concluir con ejemplos de traducción del diccionario entrenado al español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Planteamiento de la solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica voy a proponer la traducción del hebreo al español. Esto porque al ser un idioma de caracteres diferentes al español y no venir de la misma familia linguística, constituye un gran reto (lo único que se conserva en digital son los números arábigos: 0,1,2,3,4,5,6,7,8,9). Además puede resultar útil para los sacerdotes y teólogos, ya que son las personas que sí llegan a estudiar documentos en este idioma (además de quien quiera hacer turismo en Tierra Santa o para estudiosos del judaísmo).\n",
    "\n",
    "Para esto se consiguieron datasets de Kaggle para formar el diccionario: https://www.kaggle.com/datasets/miguelcorraljr/ted-ultimate-dataset. Sólo que al ser por separado sobre Ted Talks, hay que manipularlos un poco para formar un sólo dataset-diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import load\n",
    "from keras_transformer import get_model, decode\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a manipular los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esp = pd.read_csv(\"ted_talks_es.csv\", encoding=\"utf-8\")\n",
    "df_heb = pd.read_csv(\"ted_talks_he.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>views</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al Gore sobre cómo evitar la crisis climática</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gore focused the world’...</td>\n",
       "      <td>3523396</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>{243: 'New thinking on the climate crisis', 54...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_averting_the...</td>\n",
       "      <td>Con el mismo humor y humanidad que irradió en ...</td>\n",
       "      <td>Muchas gracias Chris. Y es en verdad un gran h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>David Pogue dice \"La Simplicidad Vende\"</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>{0: 'David Pogue'}</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>{0: 'David Pogue is the personal technology co...</td>\n",
       "      <td>1920803</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>{1725: '10 top time-saving tech tips', 2274: '...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_simplici...</td>\n",
       "      <td>El columnista del New York Times, David Pogue,...</td>\n",
       "      <td>Hola contestadora automática, mi vieja amiga. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Un recorrido por la renovación urbana de la ma...</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>{0: 'Majora Carter'}</td>\n",
       "      <td>{0: ['activist for environmental justice']}</td>\n",
       "      <td>{0: 'Majora Carter redefined the field of envi...</td>\n",
       "      <td>2664029</td>\n",
       "      <td>2006-02-26</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1116</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>{1041: '3 stories of local eco-entrepreneurshi...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_greeni...</td>\n",
       "      <td>En una charla altamente emotiva, la activista ...</td>\n",
       "      <td>Si están presentes aquí hoy, y estoy muy conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>Ken Robinson dice que las escuelas matan la cr...</td>\n",
       "      <td>Sir Ken Robinson</td>\n",
       "      <td>{0: 'Sir Ken Robinson'}</td>\n",
       "      <td>{0: ['author', 'educator']}</td>\n",
       "      <td>{0: \"Creativity expert Sir Ken Robinson challe...</td>\n",
       "      <td>65052534</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...</td>\n",
       "      <td>4931.0</td>\n",
       "      <td>1164</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>{865: 'Bring on the learning revolution!', 173...</td>\n",
       "      <td>https://www.ted.com/talks/sir_ken_robinson_do_...</td>\n",
       "      <td>Sir Ken Robinson plantea de manera entretenida...</td>\n",
       "      <td>Buenos días. ¿Cómo están? Ha sido increíble, ¿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>Hans Rosling nos muestra las mejores estadísti...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert; data visionary']}</td>\n",
       "      <td>{0: 'In Hans Rosling’s hands, data sings. Glob...</td>\n",
       "      <td>14501766</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>{2056: \"Own your body's data\", 2296: 'A visual...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_the_bes...</td>\n",
       "      <td>Una manera única de presentar datos. Con la en...</td>\n",
       "      <td>Hace unos 10 años, emprendí la tarea de enseña...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                                              title  \\\n",
       "0        1      Al Gore sobre cómo evitar la crisis climática   \n",
       "1        7            David Pogue dice \"La Simplicidad Vende\"   \n",
       "2       53  Un recorrido por la renovación urbana de la ma...   \n",
       "3       66  Ken Robinson dice que las escuelas matan la cr...   \n",
       "4       92  Hans Rosling nos muestra las mejores estadísti...   \n",
       "\n",
       "          speaker_1             all_speakers  \\\n",
       "0           Al Gore           {0: 'Al Gore'}   \n",
       "1       David Pogue       {0: 'David Pogue'}   \n",
       "2     Majora Carter     {0: 'Majora Carter'}   \n",
       "3  Sir Ken Robinson  {0: 'Sir Ken Robinson'}   \n",
       "4      Hans Rosling      {0: 'Hans Rosling'}   \n",
       "\n",
       "                                     occupations  \\\n",
       "0                      {0: ['climate advocate']}   \n",
       "1                  {0: ['technology columnist']}   \n",
       "2    {0: ['activist for environmental justice']}   \n",
       "3                    {0: ['author', 'educator']}   \n",
       "4  {0: ['global health expert; data visionary']}   \n",
       "\n",
       "                                      about_speakers     views recorded_date  \\\n",
       "0  {0: 'Nobel Laureate Al Gore focused the world’...   3523396    2006-02-25   \n",
       "1  {0: 'David Pogue is the personal technology co...   1920803    2006-02-24   \n",
       "2  {0: 'Majora Carter redefined the field of envi...   2664029    2006-02-26   \n",
       "3  {0: \"Creativity expert Sir Ken Robinson challe...  65052534    2006-02-25   \n",
       "4  {0: 'In Hans Rosling’s hands, data sings. Glob...  14501766    2006-02-22   \n",
       "\n",
       "  published_date    event native_lang  \\\n",
       "0     2006-06-27  TED2006          en   \n",
       "1     2006-06-27  TED2006          en   \n",
       "2     2006-06-27  TED2006          en   \n",
       "3     2006-06-27  TED2006          en   \n",
       "4     2006-06-27  TED2006          en   \n",
       "\n",
       "                                      available_lang  comments  duration  \\\n",
       "0  ['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...     272.0       977   \n",
       "1  ['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...     124.0      1286   \n",
       "2  ['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...     219.0      1116   \n",
       "3  ['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...    4931.0      1164   \n",
       "4  ['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...     628.0      1190   \n",
       "\n",
       "                                              topics  \\\n",
       "0  ['alternative energy', 'cars', 'climate change...   \n",
       "1  ['computers', 'entertainment', 'interface desi...   \n",
       "2  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "3  ['children', 'creativity', 'culture', 'dance',...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  {243: 'New thinking on the climate crisis', 54...   \n",
       "1  {1725: '10 top time-saving tech tips', 2274: '...   \n",
       "2  {1041: '3 stories of local eco-entrepreneurshi...   \n",
       "3  {865: 'Bring on the learning revolution!', 173...   \n",
       "4  {2056: \"Own your body's data\", 2296: 'A visual...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.ted.com/talks/al_gore_averting_the...   \n",
       "1  https://www.ted.com/talks/david_pogue_simplici...   \n",
       "2  https://www.ted.com/talks/majora_carter_greeni...   \n",
       "3  https://www.ted.com/talks/sir_ken_robinson_do_...   \n",
       "4  https://www.ted.com/talks/hans_rosling_the_bes...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Con el mismo humor y humanidad que irradió en ...   \n",
       "1  El columnista del New York Times, David Pogue,...   \n",
       "2  En una charla altamente emotiva, la activista ...   \n",
       "3  Sir Ken Robinson plantea de manera entretenida...   \n",
       "4  Una manera única de presentar datos. Con la en...   \n",
       "\n",
       "                                          transcript  \n",
       "0  Muchas gracias Chris. Y es en verdad un gran h...  \n",
       "1  Hola contestadora automática, mi vieja amiga. ...  \n",
       "2  Si están presentes aquí hoy, y estoy muy conte...  \n",
       "3  Buenos días. ¿Cómo están? Ha sido increíble, ¿...  \n",
       "4  Hace unos 10 años, emprendí la tarea de enseña...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_esp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>views</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>אל גור מדבר על פתרונות ביתים למשבר האקלימי</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gore focused the world’...</td>\n",
       "      <td>3523396</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>{243: 'New thinking on the climate crisis', 54...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_averting_the...</td>\n",
       "      <td>סגן נשיא ארה\"ב לשעבר אל גור מונה חמישה עשר דרכ...</td>\n",
       "      <td>תודה רבה כריס. זה אכן כבוד גדול לעלות על הבמה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>דיוויד פוג אומר ש-\"פשטות מוכרת\"</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>{0: 'David Pogue'}</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>{0: 'David Pogue is the personal technology co...</td>\n",
       "      <td>1920845</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>{1725: '10 top time-saving tech tips', 2274: '...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_simplici...</td>\n",
       "      <td>כתב ה\"ניו יורק טיימס\" דיוויד פוג לוקח מטרה אל ...</td>\n",
       "      <td>משיבון, חבריי היקר. (צחוק) התקשרתי לתמיכה טכני...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>סיפורה של מג'ורה קרטר על התחדשות עירונית</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>{0: 'Majora Carter'}</td>\n",
       "      <td>{0: ['activist for environmental justice']}</td>\n",
       "      <td>{0: 'Majora Carter redefined the field of envi...</td>\n",
       "      <td>2664034</td>\n",
       "      <td>2006-02-26</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1116</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>{1041: '3 stories of local eco-entrepreneurshi...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_greeni...</td>\n",
       "      <td>בשיחה טעונה רגשית, הפעילה זוכת פרס מקרתור מג'ו...</td>\n",
       "      <td>אם אתם כאן היום, ואני שמחה שאתם כאן' כבר שמעתם...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>איך בתי הספר הורגים את היצירתיות</td>\n",
       "      <td>Sir Ken Robinson</td>\n",
       "      <td>{0: 'Sir Ken Robinson'}</td>\n",
       "      <td>{0: ['author', 'educator']}</td>\n",
       "      <td>{0: \"Creativity expert Sir Ken Robinson challe...</td>\n",
       "      <td>65052109</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...</td>\n",
       "      <td>4931.0</td>\n",
       "      <td>1164</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>{865: 'Bring on the learning revolution!', 173...</td>\n",
       "      <td>https://www.ted.com/talks/sir_ken_robinson_do_...</td>\n",
       "      <td>סר קן רובינסון מציג טיעון משעשע ומרגש ביותר בז...</td>\n",
       "      <td>בוקר טוב. מה שלומכם? היה נהדר, נכון? היה כיף א...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>הנס רוסלינג מציג את הנתונים הכי טובים שיצא לכם...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert; data visionary']}</td>\n",
       "      <td>{0: 'In Hans Rosling’s hands, data sings. Glob...</td>\n",
       "      <td>14501647</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>{2056: \"Own your body's data\", 2296: 'A visual...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_the_bes...</td>\n",
       "      <td>עוד לא ראיתם נתונים מוצגים בדרך זו. באמצעות הד...</td>\n",
       "      <td>לפני כעשר שנים לקחתי לעצמי את המשימה ללמד סטוד...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                                              title  \\\n",
       "0        1         אל גור מדבר על פתרונות ביתים למשבר האקלימי   \n",
       "1        7                    דיוויד פוג אומר ש-\"פשטות מוכרת\"   \n",
       "2       53           סיפורה של מג'ורה קרטר על התחדשות עירונית   \n",
       "3       66                   איך בתי הספר הורגים את היצירתיות   \n",
       "4       92  הנס רוסלינג מציג את הנתונים הכי טובים שיצא לכם...   \n",
       "\n",
       "          speaker_1             all_speakers  \\\n",
       "0           Al Gore           {0: 'Al Gore'}   \n",
       "1       David Pogue       {0: 'David Pogue'}   \n",
       "2     Majora Carter     {0: 'Majora Carter'}   \n",
       "3  Sir Ken Robinson  {0: 'Sir Ken Robinson'}   \n",
       "4      Hans Rosling      {0: 'Hans Rosling'}   \n",
       "\n",
       "                                     occupations  \\\n",
       "0                      {0: ['climate advocate']}   \n",
       "1                  {0: ['technology columnist']}   \n",
       "2    {0: ['activist for environmental justice']}   \n",
       "3                    {0: ['author', 'educator']}   \n",
       "4  {0: ['global health expert; data visionary']}   \n",
       "\n",
       "                                      about_speakers     views recorded_date  \\\n",
       "0  {0: 'Nobel Laureate Al Gore focused the world’...   3523396    2006-02-25   \n",
       "1  {0: 'David Pogue is the personal technology co...   1920845    2006-02-24   \n",
       "2  {0: 'Majora Carter redefined the field of envi...   2664034    2006-02-26   \n",
       "3  {0: \"Creativity expert Sir Ken Robinson challe...  65052109    2006-02-25   \n",
       "4  {0: 'In Hans Rosling’s hands, data sings. Glob...  14501647    2006-02-22   \n",
       "\n",
       "  published_date    event native_lang  \\\n",
       "0     2006-06-27  TED2006          en   \n",
       "1     2006-06-27  TED2006          en   \n",
       "2     2006-06-27  TED2006          en   \n",
       "3     2006-06-27  TED2006          en   \n",
       "4     2006-06-27  TED2006          en   \n",
       "\n",
       "                                      available_lang  comments  duration  \\\n",
       "0  ['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...     272.0       977   \n",
       "1  ['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...     124.0      1286   \n",
       "2  ['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...     219.0      1116   \n",
       "3  ['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...    4931.0      1164   \n",
       "4  ['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...     628.0      1190   \n",
       "\n",
       "                                              topics  \\\n",
       "0  ['alternative energy', 'cars', 'climate change...   \n",
       "1  ['computers', 'entertainment', 'interface desi...   \n",
       "2  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "3  ['children', 'creativity', 'culture', 'dance',...   \n",
       "4  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  {243: 'New thinking on the climate crisis', 54...   \n",
       "1  {1725: '10 top time-saving tech tips', 2274: '...   \n",
       "2  {1041: '3 stories of local eco-entrepreneurshi...   \n",
       "3  {865: 'Bring on the learning revolution!', 173...   \n",
       "4  {2056: \"Own your body's data\", 2296: 'A visual...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.ted.com/talks/al_gore_averting_the...   \n",
       "1  https://www.ted.com/talks/david_pogue_simplici...   \n",
       "2  https://www.ted.com/talks/majora_carter_greeni...   \n",
       "3  https://www.ted.com/talks/sir_ken_robinson_do_...   \n",
       "4  https://www.ted.com/talks/hans_rosling_the_bes...   \n",
       "\n",
       "                                         description  \\\n",
       "0  סגן נשיא ארה\"ב לשעבר אל גור מונה חמישה עשר דרכ...   \n",
       "1  כתב ה\"ניו יורק טיימס\" דיוויד פוג לוקח מטרה אל ...   \n",
       "2  בשיחה טעונה רגשית, הפעילה זוכת פרס מקרתור מג'ו...   \n",
       "3  סר קן רובינסון מציג טיעון משעשע ומרגש ביותר בז...   \n",
       "4  עוד לא ראיתם נתונים מוצגים בדרך זו. באמצעות הד...   \n",
       "\n",
       "                                          transcript  \n",
       "0  תודה רבה כריס. זה אכן כבוד גדול לעלות על הבמה ...  \n",
       "1  משיבון, חבריי היקר. (צחוק) התקשרתי לתמיכה טכני...  \n",
       "2  אם אתם כאן היום, ואני שמחה שאתם כאן' כבר שמעתם...  \n",
       "3  בוקר טוב. מה שלומכם? היה נהדר, נכון? היה כיף א...  \n",
       "4  לפני כעשר שנים לקחתי לעצמי את המשימה ללמד סטוד...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar la columna de title. Es cierto que podríamos usar también las columnas de description y de transcript. Sin embargo, el dataset se haría demasiado grande como para entrenar (se intentó hacer con el dataset completo y no se pudo entrenar la red ni en el servidor, ni en mi computadora personal). Esto porque las palabras del transcript son demasiadas y las de la description incluyen links y otros caracteres que le generan ruido al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = pd.concat([df_heb[\"title\"], df_esp[\"title\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.columns = [\"Hebreo\", \"Español\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3921 entries, 0 to 3920\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Hebreo   3298 non-null   object\n",
      " 1   Español  3921 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 61.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_title.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3298 entries, 0 to 3297\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Hebreo   3298 non-null   object\n",
      " 1   Español  3298 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 77.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_title.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque sean pocos datos podemos realizar el ejercicio con este dataset, veamos hasta qué punto podemos optimizar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.to_csv(\"Hebreo_Español.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí podemos pasar a la arquitectura del transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hebreo_Español.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tokens = [sentence.split(\" \") for sentence in df.iloc[:,0]]\n",
    "target_tokens = [sentence.split(\" \") for sentence in df.iloc[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['בימים', 'של', 'חוסר', 'וודאות,', 'חישבו', 'כמו', 'אמא']\n",
      "['¿Puedes', 'resolver', 'el', 'enigma', 'de', 'la', 'sala', 'de', 'control?', '-', 'Dennis', 'Shasha']\n"
     ]
    }
   ],
   "source": [
    "print(source_tokens[-1])\n",
    "print(target_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_token_dict(token_list):\n",
    "  token_dict = {\n",
    "      '<PAD>': 0,\n",
    "      '<START>': 1,\n",
    "      '<END>': 2\n",
    "  }\n",
    "  for tokens in token_list:\n",
    "    for token in tokens:\n",
    "      if token not in token_dict:\n",
    "        token_dict[token] = len(token_dict)\n",
    "  return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_token_dict = build_token_dict(source_tokens)\n",
    "target_token_dict = build_token_dict(target_tokens)\n",
    "target_token_dict_inv = {v:k for k,v in target_token_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos las frases del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "decoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
    "output_tokens = [tokens + ['<END>'] for tokens in target_tokens]\n",
    "\n",
    "source_max_len = max(map(len, encoder_tokens))\n",
    "target_max_len = max(map(len, decoder_tokens))\n",
    "\n",
    "encoder_tokens = [tokens + ['<PAD>']*(source_max_len-len(tokens)) for tokens in encoder_tokens]\n",
    "decoder_tokens = [tokens + ['<PAD>']*(target_max_len-len(tokens)) for tokens in decoder_tokens]\n",
    "output_tokens = [tokens + ['<PAD>']*(target_max_len-len(tokens)) for tokens in output_tokens ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encoder_tokens]\n",
    "decoder_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decoder_tokens]\n",
    "output_decoded = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora finalmente podemos pasar a la creación del transformer.\n",
    "\n",
    "En primera instancia vamos a retomar la arquitectura que usamos en la sesión del traductor inglés-español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Encoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-Token-Embedding (Embed  [(None, None, 32),  341504      ['Encoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 32)]                                                     \n",
      "                                                                                                  \n",
      " Encoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Encoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-Token-Embedding (Embed  [(None, None, 32),  341504      ['Decoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 32)]                                                     \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Decoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Decoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-1-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-1-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-2-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-2-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-Output (EmbeddingSim)  (None, None, 10672)  10672       ['Decoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Decoder-Token-Embedding[0][1]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 753,072\n",
      "Trainable params: 753,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model(\n",
    "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
    "    embed_dim=32,\n",
    "    encoder_num=2,\n",
    "    decoder_num=2,\n",
    "    head_num=4,\n",
    "    hidden_dim=128,\n",
    "    dropout_rate=0.05,\n",
    "    use_same_embed=False,\n",
    ")\n",
    "\n",
    "model1.compile(\"adam\", \"sparse_categorical_crossentropy\")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que usando los títulos no llegamos ni al millón de parámetros. En cambio si usábamos el dataset completo eran más de 24 millones, usando las trasncripciones eran más de 8 millones. Por lo tanto, con este dataset aunque sea pequeño, nos permite experimentar con los parámetros de la arquitectura transformer, que es el objetivo de este trabajo.\n",
    "\n",
    "Nos preparamos para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.array(encoder_input), np.array(decoder_input)]\n",
    "y = np.array(output_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 33s 89ms/step - loss: 4.0127\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 3.2482\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 3.0201\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 2.8864\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 2.7887\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 2.7022\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 2.6086\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 11s 102ms/step - loss: 2.5167\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 2.4331\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 2.3514\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 2.2691\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 2.1897\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 2.1121\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 2.0394\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 1.9638\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x, y, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los valores de la función de costo le podemos dejar entrenar otras 15 épocas, ya que todavía la está disminuyendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 9s 86ms/step - loss: 1.8895\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 1.8129\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 1.7348\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 9s 82ms/step - loss: 1.6595\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 1.5959\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 1.5201\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 1.4363\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 1.3685\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 1.2965\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 1.2298\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 1.1542\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 1.0807\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 1.0185\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.9475\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 0.8993\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x, y, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la función de pérdida sigue reduciendo (no se estanca mostrando sobreajuste) podemos seguir el entrenamiento e incluso con más épocas para lograr que termine de entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.8308\n",
      "Epoch 2/25\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.7699\n",
      "Epoch 3/25\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 0.7259\n",
      "Epoch 4/25\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.6789\n",
      "Epoch 5/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.6273\n",
      "Epoch 6/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.5803\n",
      "Epoch 7/25\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5394\n",
      "Epoch 8/25\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5031\n",
      "Epoch 9/25\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.4717\n",
      "Epoch 10/25\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 0.4339\n",
      "Epoch 11/25\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.4127\n",
      "Epoch 12/25\n",
      "104/104 [==============================] - 9s 86ms/step - loss: 0.3837\n",
      "Epoch 13/25\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.3482\n",
      "Epoch 14/25\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 0.3299\n",
      "Epoch 15/25\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.3120\n",
      "Epoch 16/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.2922\n",
      "Epoch 17/25\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 0.2703\n",
      "Epoch 18/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.2505\n",
      "Epoch 19/25\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.2481\n",
      "Epoch 20/25\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.2303\n",
      "Epoch 21/25\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 0.2104\n",
      "Epoch 22/25\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 0.1953\n",
      "Epoch 23/25\n",
      "104/104 [==============================] - 9s 82ms/step - loss: 0.1876\n",
      "Epoch 24/25\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 0.1766\n",
      "Epoch 25/25\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 0.1646\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x, y, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función de pérdida menor a 0.20, en este caso en 0.16 nuestro modelo podemos guardarlo para ejecutar pruebas en los ejemplos de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"modelo1_tarea5.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos entonces un modelo con una arquitectura del transformer más robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Encoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-Token-Embedding (Embed  [(None, None, 128),  1366016    ['Encoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 128)]                                                    \n",
      "                                                                                                  \n",
      " Encoder-Embedding (TrigPosEmbe  (None, None, 128)   0           ['Encoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-3-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-4-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-4-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-4-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-5-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-5-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-5-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-5-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-5-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-5-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-5-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-6-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-6-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-6-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-6-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-6-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-6-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-6-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-7-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-7-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-7-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-7-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-7-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Encoder-7-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-Token-Embedding (Embed  [(None, None, 128),  1366016    ['Decoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 128)]                                                    \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, None, 128)   0           ['Encoder-7-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-8-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-Embedding (TrigPosEmbe  (None, None, 128)   0           ['Decoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, None, 128)   256         ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward (FeedFor  (None, None, 128)   33024       ['Encoder-8-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Dropout   (None, None, 128)   0           ['Encoder-8-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Decoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Add (Add  (None, None, 128)   0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Norm (La  (None, None, 128)   256         ['Encoder-8-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-1-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-1-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-2-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-2-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-3-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-3-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-3-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-3-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-3-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-3-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-3-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-4-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-4-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-4-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-4-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-4-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-4-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-4-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-4-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-5-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-4-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-5-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-5-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-5-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-5-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-5-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-5-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-5-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-5-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-5-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-5-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-5-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-5-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-5-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-5-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-5-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-5-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-5-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-5-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-6-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-5-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-6-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-6-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-6-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-6-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-6-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-6-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-6-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-6-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-6-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-6-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-6-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-6-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-6-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-6-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-6-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-6-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-6-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-6-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-7-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-6-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-7-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-7-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-7-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-7-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-7-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-7-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-7-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-7-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-7-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-7-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-7-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-7-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-7-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-7-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-7-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-7-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-7-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadSelfAttenti  (None, None, 128)   66048       ['Decoder-7-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-8-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadSelfAttenti  (None, None, 128)   0           ['Decoder-7-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-8-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadSelfAttenti  (None, None, 128)   256         ['Decoder-8-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadQueryAttent  (None, None, 128)   66048       ['Decoder-8-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-8-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadQueryAttent  (None, None, 128)   0           ['Decoder-8-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-8-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-8-MultiHeadQueryAttent  (None, None, 128)   256         ['Decoder-8-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-8-FeedForward (FeedFor  (None, None, 128)   33024       ['Decoder-8-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-8-FeedForward-Dropout   (None, None, 128)   0           ['Decoder-8-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-8-FeedForward-Add (Add  (None, None, 128)   0           ['Decoder-8-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-8-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-8-FeedForward-Norm (La  (None, None, 128)   256         ['Decoder-8-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-Output (EmbeddingSim)  (None, None, 10672)  10672       ['Decoder-8-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Decoder-Token-Embedding[0][1]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,866,480\n",
      "Trainable params: 4,866,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = get_model(\n",
    "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
    "    embed_dim=128, # aumentamos la dimensionalidad de los vectores de palabras\n",
    "    encoder_num=8, # subimos las cantidades de encoder y decoders al momento de procesar los vectores\n",
    "    decoder_num=8,\n",
    "    head_num=16, # aumentamos también el número de cabezas\n",
    "    hidden_dim=128, # dejamos igual las capas de la red neuronal interna\n",
    "    dropout_rate=0.05,\n",
    "    use_same_embed=False,\n",
    ")\n",
    "\n",
    "model2.compile(\"adam\", \"sparse_categorical_crossentropy\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si puede entrenar con esos 4 millones de parámetros (le daremos muchas épocas de una vez para no tener que repetir el entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "104/104 [==============================] - 108s 416ms/step - loss: 3.6134\n",
      "Epoch 2/60\n",
      "104/104 [==============================] - 43s 418ms/step - loss: 3.3421\n",
      "Epoch 3/60\n",
      "104/104 [==============================] - 25s 239ms/step - loss: 3.3343\n",
      "Epoch 4/60\n",
      "104/104 [==============================] - 19s 186ms/step - loss: 3.3279\n",
      "Epoch 5/60\n",
      "104/104 [==============================] - 18s 170ms/step - loss: 3.3000\n",
      "Epoch 6/60\n",
      "104/104 [==============================] - 19s 179ms/step - loss: 3.2250\n",
      "Epoch 7/60\n",
      "104/104 [==============================] - 19s 182ms/step - loss: 3.1800\n",
      "Epoch 8/60\n",
      "104/104 [==============================] - 18s 177ms/step - loss: 3.1454\n",
      "Epoch 9/60\n",
      "104/104 [==============================] - 18s 170ms/step - loss: 3.1240\n",
      "Epoch 10/60\n",
      "104/104 [==============================] - 20s 196ms/step - loss: 3.1047\n",
      "Epoch 11/60\n",
      "104/104 [==============================] - 18s 175ms/step - loss: 3.0926\n",
      "Epoch 12/60\n",
      "104/104 [==============================] - 18s 171ms/step - loss: 3.0831\n",
      "Epoch 13/60\n",
      "104/104 [==============================] - 19s 178ms/step - loss: 3.0705\n",
      "Epoch 14/60\n",
      "104/104 [==============================] - 20s 194ms/step - loss: 3.0612\n",
      "Epoch 15/60\n",
      "104/104 [==============================] - 18s 176ms/step - loss: 3.0519\n",
      "Epoch 16/60\n",
      "104/104 [==============================] - 19s 182ms/step - loss: 3.0472\n",
      "Epoch 17/60\n",
      "104/104 [==============================] - 19s 186ms/step - loss: 3.0399\n",
      "Epoch 18/60\n",
      "104/104 [==============================] - 21s 199ms/step - loss: 3.0354\n",
      "Epoch 19/60\n",
      "104/104 [==============================] - 18s 176ms/step - loss: 3.0336\n",
      "Epoch 20/60\n",
      "104/104 [==============================] - 21s 199ms/step - loss: 3.0261\n",
      "Epoch 21/60\n",
      "104/104 [==============================] - 20s 193ms/step - loss: 3.0217\n",
      "Epoch 22/60\n",
      "104/104 [==============================] - 21s 200ms/step - loss: 3.0177\n",
      "Epoch 23/60\n",
      "104/104 [==============================] - 20s 195ms/step - loss: 3.0141\n",
      "Epoch 24/60\n",
      "104/104 [==============================] - 20s 189ms/step - loss: 3.0062\n",
      "Epoch 25/60\n",
      "104/104 [==============================] - 21s 202ms/step - loss: 3.0028\n",
      "Epoch 26/60\n",
      "104/104 [==============================] - 22s 210ms/step - loss: 3.0011\n",
      "Epoch 27/60\n",
      "104/104 [==============================] - 20s 189ms/step - loss: 2.9977\n",
      "Epoch 28/60\n",
      "104/104 [==============================] - 20s 191ms/step - loss: 2.9918\n",
      "Epoch 29/60\n",
      "104/104 [==============================] - 23s 220ms/step - loss: 2.9892\n",
      "Epoch 30/60\n",
      "104/104 [==============================] - 19s 183ms/step - loss: 2.9852\n",
      "Epoch 31/60\n",
      "104/104 [==============================] - 18s 177ms/step - loss: 2.9805\n",
      "Epoch 32/60\n",
      "104/104 [==============================] - 21s 203ms/step - loss: 2.9778\n",
      "Epoch 33/60\n",
      "104/104 [==============================] - 19s 187ms/step - loss: 2.9862\n",
      "Epoch 34/60\n",
      "104/104 [==============================] - 20s 196ms/step - loss: 2.9691\n",
      "Epoch 35/60\n",
      "104/104 [==============================] - 20s 192ms/step - loss: 2.9749\n",
      "Epoch 36/60\n",
      "104/104 [==============================] - 18s 174ms/step - loss: 2.9663\n",
      "Epoch 37/60\n",
      "104/104 [==============================] - 19s 179ms/step - loss: 2.9664\n",
      "Epoch 38/60\n",
      "104/104 [==============================] - 19s 182ms/step - loss: 2.9602\n",
      "Epoch 39/60\n",
      "104/104 [==============================] - 21s 201ms/step - loss: 2.9593\n",
      "Epoch 40/60\n",
      "104/104 [==============================] - 18s 177ms/step - loss: 2.9557\n",
      "Epoch 41/60\n",
      "104/104 [==============================] - 20s 188ms/step - loss: 2.9576\n",
      "Epoch 42/60\n",
      "104/104 [==============================] - 21s 199ms/step - loss: 2.9539\n",
      "Epoch 43/60\n",
      "104/104 [==============================] - 18s 176ms/step - loss: 2.9475\n",
      "Epoch 44/60\n",
      "104/104 [==============================] - 19s 186ms/step - loss: 2.9505\n",
      "Epoch 45/60\n",
      "104/104 [==============================] - 19s 186ms/step - loss: 2.9485\n",
      "Epoch 46/60\n",
      "104/104 [==============================] - 22s 216ms/step - loss: 2.9445\n",
      "Epoch 47/60\n",
      "104/104 [==============================] - 19s 184ms/step - loss: 2.9363\n",
      "Epoch 48/60\n",
      "104/104 [==============================] - 17s 167ms/step - loss: 2.9347\n",
      "Epoch 49/60\n",
      "104/104 [==============================] - 19s 185ms/step - loss: 2.9810\n",
      "Epoch 50/60\n",
      "104/104 [==============================] - 20s 188ms/step - loss: 2.9341\n",
      "Epoch 51/60\n",
      "104/104 [==============================] - 20s 191ms/step - loss: 2.9311\n",
      "Epoch 52/60\n",
      "104/104 [==============================] - 21s 201ms/step - loss: 2.9301\n",
      "Epoch 53/60\n",
      "104/104 [==============================] - 21s 202ms/step - loss: 2.9239\n",
      "Epoch 54/60\n",
      "104/104 [==============================] - 18s 173ms/step - loss: 2.9192\n",
      "Epoch 55/60\n",
      "104/104 [==============================] - 21s 199ms/step - loss: 2.9200\n",
      "Epoch 56/60\n",
      "104/104 [==============================] - 18s 173ms/step - loss: 2.9135\n",
      "Epoch 57/60\n",
      "104/104 [==============================] - 20s 196ms/step - loss: 2.9097\n",
      "Epoch 58/60\n",
      "104/104 [==============================] - 19s 184ms/step - loss: 2.9165\n",
      "Epoch 59/60\n",
      "104/104 [==============================] - 19s 182ms/step - loss: 2.9057\n",
      "Epoch 60/60\n",
      "104/104 [==============================] - 19s 180ms/step - loss: 2.9076\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x, y, epochs=60, batch_size=32) # mantenemos el mismo número de instancias por lote para no subir más aun los parámetros del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver este modelo siendo mucho más complejo, tiene un entrenamiento mucho más lento. Con 60 épocas casi no reduce la pérdida, por lo que necesitaría entrenamientos mucho más largos. Justo si lo graficamos vemos que incluso pareciera que comienza a sobreajustar, pero en realidad lo que pasa es que para ajustar cada parte de la arquitectura de la red, es necesario un entrenamiento de muchas épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "loss = pd.DataFrame({'Epoch': range(1, len(history2.history['loss']) + 1), 'Loss': history2.history['loss']})\n",
    "sns.lineplot(data=loss, x='Epoch', y='Loss')\n",
    "\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Entrenamiento de la función de pérdida a lo largo de las épocas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"modelo2_tarea5.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos un modelo que sea un punto medio entre los 2 que ya tenemos: no tan pesado como este último pero tampoco tan ligero como el primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Encoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-Token-Embedding (Embed  [(None, None, 64),  683008      ['Encoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 64)]                                                     \n",
      "                                                                                                  \n",
      " Encoder-Embedding (TrigPosEmbe  (None, None, 64)    0           ['Encoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Encoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 64)    128         ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, None, 64)    33088       ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, None, 64)    0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, None, 64)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, None, 64)    128         ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 64)    128         ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, None, 64)    33088       ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, None, 64)    0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, None, 64)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, None, 64)    128         ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Encoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, None, 64)    128         ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward (FeedFor  (None, None, 64)    33088       ['Encoder-3-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Dropout   (None, None, 64)    0           ['Encoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Add (Add  (None, None, 64)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Norm (La  (None, None, 64)    128         ['Encoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Encoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-Token-Embedding (Embed  [(None, None, 64),  683008      ['Decoder-Input[0][0]']          \n",
      " dingRet)                        (10672, 64)]                                                     \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 64)    0           ['Encoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-Embedding (TrigPosEmbe  (None, None, 64)    0           ['Decoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, None, 64)    128         ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Decoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward (FeedFor  (None, None, 64)    33088       ['Encoder-4-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Dropout   (None, None, 64)    0           ['Encoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Decoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Add (Add  (None, None, 64)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 64)    128         ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Norm (La  (None, None, 64)    128         ['Encoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 64)    16640       ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-1-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 64)    128         ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward (FeedFor  (None, None, 64)    33088       ['Decoder-1-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Dropout   (None, None, 64)    0           ['Decoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Add (Add  (None, None, 64)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Norm (La  (None, None, 64)    128         ['Decoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Decoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 64)    128         ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 64)    16640       ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-2-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 64)    128         ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward (FeedFor  (None, None, 64)    33088       ['Decoder-2-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Dropout   (None, None, 64)    0           ['Decoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Add (Add  (None, None, 64)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Norm (La  (None, None, 64)    128         ['Decoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Decoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadSelfAttenti  (None, None, 64)    128         ['Decoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 64)    16640       ['Decoder-3-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-3-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-3-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-3-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-3-MultiHeadQueryAttent  (None, None, 64)    128         ['Decoder-3-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward (FeedFor  (None, None, 64)    33088       ['Decoder-3-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Dropout   (None, None, 64)    0           ['Decoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Add (Add  (None, None, 64)    0           ['Decoder-3-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-3-FeedForward-Norm (La  (None, None, 64)    128         ['Decoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 64)    16640       ['Decoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 64)    0           ['Decoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadSelfAttenti  (None, None, 64)    128         ['Decoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 64)    16640       ['Decoder-4-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-4-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 64)    0           ['Decoder-4-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-4-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-4-MultiHeadQueryAttent  (None, None, 64)    128         ['Decoder-4-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward (FeedFor  (None, None, 64)    33088       ['Decoder-4-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Dropout   (None, None, 64)    0           ['Decoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Add (Add  (None, None, 64)    0           ['Decoder-4-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-4-FeedForward-Norm (La  (None, None, 64)    128         ['Decoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-Output (EmbeddingSim)  (None, None, 10672)  10672       ['Decoder-4-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Decoder-Token-Embedding[0][1]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,843,632\n",
      "Trainable params: 1,843,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = get_model(\n",
    "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
    "    embed_dim=64, \n",
    "    encoder_num=4, \n",
    "    decoder_num=4,\n",
    "    head_num=8, \n",
    "    hidden_dim=256, # esta es la única capa que aumentamos\n",
    "    dropout_rate=0.05,\n",
    "    use_same_embed=False,\n",
    ")\n",
    "\n",
    "model3.compile(\"adam\", \"sparse_categorical_crossentropy\")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podemos ver que tenemos menos de 2 millones de parámetros, por lo que debería ser más ligero que el segundo, pero más complejo que el primero (ya que no llegaba al millón).\n",
    "\n",
    "Para este último vamos a lo más robusto por ahora: 100 épocas para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104/104 [==============================] - 26s 84ms/step - loss: 3.7639\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 3.2883\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 9s 88ms/step - loss: 3.1383\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 3.0016\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 2.9347\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 2.8539\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 2.7614\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 2.6756\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 2.5936\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 2.5176\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 2.4529\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 2.3825\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 8s 79ms/step - loss: 2.3285\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 8s 80ms/step - loss: 2.2578\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 2.2038\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 2.1446\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 2.0875\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 2.0330\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 1.9781\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 1.9221\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 1.8841\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 1.8275\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 9s 84ms/step - loss: 1.7769\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 1.7257\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 1.6773\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 8s 80ms/step - loss: 1.6213\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 1.5800\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 1.5357\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 1.4837\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 1.4415\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 1.4088\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 1.3480\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 1.3078\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 1.2738\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 9s 88ms/step - loss: 1.2456\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 11s 106ms/step - loss: 1.1879\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 1.1493\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 1.1234\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 1.0919\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 1.0548\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 9s 88ms/step - loss: 1.0299\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 9s 86ms/step - loss: 0.9974\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.9861\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.9496\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.9160\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 12s 119ms/step - loss: 0.9041\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 0.8828\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 0.8504\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.8283\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 9s 85ms/step - loss: 0.8072\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.8012\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.7681\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.7493\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 0.7388\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.7276\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.7008\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.7162\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.6742\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.6853\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 11s 108ms/step - loss: 0.6569\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.6319\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.6161\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.5976\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.5940\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.5880\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.5831\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5738\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5759\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.5531\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.5616\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 9s 83ms/step - loss: 0.5433\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 9s 88ms/step - loss: 0.5231\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 0.5220\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.5176\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.5146\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5058\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.5003\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.4937\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.4919\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.4823\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.5105\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 0.4816\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.4870\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 0.4647\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 0.4513\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 10s 98ms/step - loss: 0.4434\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.4399\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 10s 96ms/step - loss: 0.4445\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.4482\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.4412\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 10s 91ms/step - loss: 0.4313\n",
      "Epoch 92/100\n",
      "104/104 [==============================] - 11s 101ms/step - loss: 0.4250\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 11s 102ms/step - loss: 0.4412\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 0.4460\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.4263\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 13s 121ms/step - loss: 0.4301\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.4141\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.4134\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 0.4042\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.3972\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x, y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas con 100 épocas logramos reducir la función de pérdida por debajo de 0.40. Por lo que podríamos darle más épocas al entrenamiento, pero para fines de nuestra práctica lo dejaremos hasta aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"modelo3_tarea5.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "loss = pd.DataFrame({'Epoch': range(1, len(history3.history['loss']) + 1), 'Loss': history3.history['loss']})\n",
    "sns.lineplot(data=loss, x='Epoch', y='Loss')\n",
    "\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Entrenamiento de la función de pérdida a lo largo de las épocas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ejemplo de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar algunas frases y ver qué es lo que traduce cada modelo al español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model):\n",
    "    sentence_tokens = [tokens + ['<END>', '<PAD>'] for tokens in [sentence.split(' ')]]\n",
    "    tr_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in sentence_tokens][0]\n",
    "    decoded = decode(\n",
    "        model, \n",
    "        tr_input, \n",
    "        start_token = target_token_dict['<START>'],\n",
    "        end_token = target_token_dict['<END>'],\n",
    "        pad_token = target_token_dict['<PAD>']\n",
    "    )\n",
    "\n",
    "    print('Frase original: {}'.format(sentence))\n",
    "    print('Traducción: {}'.format(' '.join(map(lambda x: target_token_dict_inv[x], decoded[1:-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase1 = \"שלום עולם\" # se supone que ahí dice hola mundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Frase original: שלום עולם\n",
      "Traducción: La tonalidad de ciencia orquesta del sueño TED TED\n"
     ]
    }
   ],
   "source": [
    "translate(frase1, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Frase original: שלום עולם\n",
      "Traducción: Cómo Cómo Cómo Cómo Cómo Cómo Cómo Cómo Cómo\n"
     ]
    }
   ],
   "source": [
    "translate(frase1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Frase original: שלום עולם\n",
      "Traducción: El arte olvidado del zoótropo\n"
     ]
    }
   ],
   "source": [
    "translate(frase1, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, las funciones de pérdida arrojan resultados completamente diferentes y algunos sin mucho sentido. Por ejemplo: el modelo 2 se nota que no logró terminar su entrenamiento y por eso regresa la misma palabra.\n",
    "\n",
    "Probemos ahora con títulos del entrenamiento para ver qué tanto aprendió lo que se le dio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase2 = \"אל גור מדבר על פתרונות ביתים למשבר האקלימי\" # este título dice: \"Al Gore sobre cómo evitar la crisis climática\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021DDACAB6D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021DDACAB6D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Frase original: אל גור מדבר על פתרונות ביתים למשבר האקלימי\n",
      "Traducción: Peter Ganson hace el lenguaje de realidad sistema climática\n"
     ]
    }
   ],
   "source": [
    "translate(frase2, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Frase original: אל גור מדבר על פתרונות ביתים למשבר האקלימי\n",
      "Traducción: Cómo Cómo Cómo Cómo Cómo Cómo Cómo Cómo Cómo\n"
     ]
    }
   ],
   "source": [
    "translate(frase2, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Frase original: אל גור מדבר על פתרונות ביתים למשבר האקלימי\n",
      "Traducción: Hans Rosling: Dejen que mi conjunto de datos cambie su mentalidad.\n"
     ]
    }
   ],
   "source": [
    "translate(frase2, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso no se logró tampoco con títulos del entrenamiento. Lo que sí se puede ver es que el segundo modelo sí le hizo falta mucho entrenamiento, ya que no logra establecer ninguna relación entre los inputs y outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con lo más simple: decir \"Hola\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase3 = \"שלום\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Frase original: שלום\n",
      "Traducción: Las fascinante humanas humanas humanas\n"
     ]
    }
   ],
   "source": [
    "translate(frase3, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Frase original: שלום\n",
      "Traducción: Michael Hansmeyer: La construcción de formas inimaginables\n"
     ]
    }
   ],
   "source": [
    "translate(frase3, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión nuestro problema fue el bajo ajuste (bias). Los modelos que realizamos no sirvieron porque no traducen cosas con sentido. Puede que el problema desde un inicio haya sido el reto tan ambicioso de traducir entre lenguajes que no comparten el mismo alfabeto (y probablemente cambie también la forma gramatical). Por lo que aquí nos damos cuenta de lo grande que es el reto de la traducción en el procesamiento de lenguaje natural: necesitas buenas fuentes de datos y conocer el idioma para poder realizar las traducciones correctamente. Aquí lo que nos limita es el conocimiento del idioma.\n",
    "\n",
    "Sin embargo, cabe destacar que para fines de conocer la arquitectura transformer, este trabajo fue muy útil: aprendimos cómo cambiar los parámetros, la manera en que los datos se transforman en la red y los requisitos para el entrenamiento. Por lo que a nivel de aprendizaje y los objetivos de la práctica sí pudimos cumplirlos.\n",
    "\n",
    "Ahora bien, otra cosa que se puede ver aquí es la falta de datasets en otros idiomas diferentes al inglés. Fue muy fácil en la sesión usar un dataset inglés-español para mostrar la práctica. Sin embargo, encontrar datasets para esta tarea fue sumamente dificil porque no los hay. El que se usó aquí es porque estaba en varios idiomas y se escogió el hebreo con el español. Sin embargo, al ser un dataset no hecho explícitamente para la traducción, puede que no sea correcto desde un inicio. Explicando así los malos resultados que tuvimos. De hecho, puede que nuestras arquitecturas fueran correctas, pero los datos de entrenamiento no. Mostrando así la importancia de los datos de entrenamiento porque pueden generar sesgos muy fuertes.\n",
    "\n",
    "De esta forma el trabajo a futuro es muy claro: dar más tiempo de entrenamiento a los modelos aquí mostrados para ver si logran mejorar el desempeño. O bien, hacer modificaciones a los datos de entrenamiento: cambiar el dataset para mantenernos en la traducción hebreo-español o cambiar el hebreo por algun otro lenguaje que comparta semejanzas con el español (de preferencia una lengua romance).\n",
    "\n",
    "Sinceramente es desalentador ver que no hay datasets en otros idiomas diferentes al inglés. Esto en la ciencia de datos genera barreras de entrada y pone obstáculos para países de lengua no inglesa para entrenar sus algoritmos. Si aquí tuvimos problemas con el hebreo, ni cómo pensar en hacerlos en lenguas indígenas mexicanas como el purépecha, náhuatl u otomí. Realmente no hay datasets de este tipo disponibles fácilmente en internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de Kaggle está en: https://www.kaggle.com/datasets/miguelcorraljr/ted-ultimate-dataset/data\n",
    "\n",
    "Se consultó también la forma de instalar keras_transformer: https://pypi.org/project/keras-transformer/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
